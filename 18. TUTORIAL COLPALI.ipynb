{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0511917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "from transformers import ColPaliForRetrieval, ColPaliProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a9f6418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc50441fb07f44c8a78be643cc4ef21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"vidore/colpali-v1.3-hf\"\n",
    "\n",
    "model = ColPaliForRetrieval.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "processor = ColPaliProcessor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d7a1939",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "def fetch_image(url):\n",
    "    r = requests.get(url, headers=headers, stream=True)\n",
    "    r.raise_for_status()\n",
    "    return Image.open(BytesIO(r.content))\n",
    "\n",
    "url1 = \"https://upload.wikimedia.org/wikipedia/commons/8/89/US-original-Declaration-1776.jpg\"\n",
    "url2 = \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Romeoandjuliet1597.jpg/500px-Romeoandjuliet1597.jpg\"\n",
    "\n",
    "images = [fetch_image(url1), fetch_image(url2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ed34aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1014x516>,\n",
       " <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x829>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cea3ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_images = processor(images=images).to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c1e0e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    image_embeddings = model(**inputs_images).embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a1d445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0884,  0.1338, -0.0273,  ...,  0.1367, -0.0625,  0.1377],\n",
       "         [-0.0162,  0.0649,  0.0444,  ..., -0.0620,  0.0342, -0.0640],\n",
       "         [ 0.0020,  0.0114, -0.0625,  ...,  0.0192, -0.0264,  0.1309],\n",
       "         ...,\n",
       "         [-0.0061,  0.0786,  0.1025,  ..., -0.0845, -0.0294, -0.0432],\n",
       "         [ 0.0282,  0.1211,  0.1289,  ..., -0.0425, -0.1128, -0.0444],\n",
       "         [ 0.0255,  0.1611,  0.1475,  ..., -0.0219, -0.1709, -0.1011]],\n",
       "\n",
       "        [[ 0.0269,  0.0048,  0.1016,  ...,  0.0713, -0.0162,  0.2002],\n",
       "         [-0.0019,  0.1045,  0.0938,  ...,  0.1270, -0.1914,  0.0830],\n",
       "         [ 0.0256,  0.1748,  0.1484,  ...,  0.0112, -0.2041, -0.1123],\n",
       "         ...,\n",
       "         [-0.0036,  0.0879,  0.0986,  ..., -0.0679, -0.0586, -0.0339],\n",
       "         [ 0.0408,  0.1084,  0.1387,  ..., -0.0237, -0.1348, -0.0439],\n",
       "         [ 0.0383,  0.1572,  0.1631,  ..., -0.0043, -0.1846, -0.0962]]],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "890442b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10e6c1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0884,  0.1338, -0.0273,  ...,  0.1367, -0.0625,  0.1377],\n",
       "        [-0.0162,  0.0649,  0.0444,  ..., -0.0620,  0.0342, -0.0640],\n",
       "        [ 0.0020,  0.0114, -0.0625,  ...,  0.0192, -0.0264,  0.1309],\n",
       "        ...,\n",
       "        [-0.0061,  0.0786,  0.1025,  ..., -0.0845, -0.0294, -0.0432],\n",
       "        [ 0.0282,  0.1211,  0.1289,  ..., -0.0425, -0.1128, -0.0444],\n",
       "        [ 0.0255,  0.1611,  0.1475,  ..., -0.0219, -0.1709, -0.1011]],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2cf6687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0269,  0.0048,  0.1016,  ...,  0.0713, -0.0162,  0.2002],\n",
       "        [-0.0019,  0.1045,  0.0938,  ...,  0.1270, -0.1914,  0.0830],\n",
       "        [ 0.0256,  0.1748,  0.1484,  ...,  0.0112, -0.2041, -0.1123],\n",
       "        ...,\n",
       "        [-0.0036,  0.0879,  0.0986,  ..., -0.0679, -0.0586, -0.0339],\n",
       "        [ 0.0408,  0.1084,  0.1387,  ..., -0.0237, -0.1348, -0.0439],\n",
       "        [ 0.0383,  0.1572,  0.1631,  ..., -0.0043, -0.1846, -0.0962]],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_embeddings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bfffbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1030, 128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "028bb83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.8379e-02,  1.3379e-01, -2.7344e-02,  6.5613e-03,  1.1621e-01,\n",
       "         1.1169e-02,  1.0889e-01, -7.8125e-02, -2.0752e-02,  2.2583e-03,\n",
       "         1.2302e-04,  4.6631e-02, -1.8921e-02,  8.1055e-02,  2.2583e-03,\n",
       "         4.6143e-02, -1.3477e-01,  6.6406e-02,  1.3281e-01, -5.4932e-02,\n",
       "         2.6245e-02,  2.8076e-02, -1.3574e-01,  7.9590e-02,  1.1279e-01,\n",
       "        -4.8340e-02,  5.1025e-02,  2.3804e-02, -9.0332e-02, -1.3672e-01,\n",
       "        -9.1309e-02,  8.9355e-02, -2.6489e-02,  1.0840e-01, -5.2734e-02,\n",
       "        -6.6406e-02,  4.1992e-02,  9.6191e-02,  1.0559e-02, -1.5723e-01,\n",
       "         1.6895e-01,  1.9897e-02,  1.6113e-02, -5.6885e-02,  1.0889e-01,\n",
       "        -1.5918e-01,  7.1777e-02, -8.8501e-03, -1.2390e-02, -9.7656e-02,\n",
       "        -5.5908e-02,  5.9082e-02, -2.2827e-02, -5.6885e-02, -3.0640e-02,\n",
       "         1.0437e-02,  1.2695e-01,  1.0645e-01,  8.0078e-02, -7.1289e-02,\n",
       "         2.5146e-02,  8.0566e-02, -1.6309e-01, -6.6406e-02,  1.9434e-01,\n",
       "         9.9609e-02, -6.2988e-02, -5.4688e-02,  1.5527e-01,  4.9072e-02,\n",
       "         3.2959e-02,  1.4844e-01, -2.2168e-01, -3.7109e-02,  1.4453e-01,\n",
       "        -4.4922e-02, -1.1841e-02,  4.1992e-02, -6.2500e-02,  5.2979e-02,\n",
       "         2.1118e-02, -2.0630e-02,  1.2598e-01,  7.2266e-02, -8.5938e-02,\n",
       "        -1.7285e-01, -1.2158e-01,  2.9907e-02,  2.4414e-03,  1.1377e-01,\n",
       "        -5.2490e-02,  5.0537e-02, -1.4404e-02,  7.3242e-02, -2.8442e-02,\n",
       "         2.6978e-02,  8.4961e-02,  9.3262e-02,  3.6133e-02,  1.4404e-02,\n",
       "         3.9795e-02, -3.1281e-03, -1.9141e-01, -2.5391e-02, -1.2158e-01,\n",
       "         7.3242e-02, -3.0762e-02, -1.4355e-01,  2.1680e-01, -1.4526e-02,\n",
       "         7.5195e-02, -6.5430e-02,  1.8066e-02, -5.2979e-02,  9.6680e-02,\n",
       "        -2.7954e-02,  9.4238e-02,  7.2021e-03, -9.4238e-02,  4.6082e-03,\n",
       "         1.6504e-01,  6.2500e-02,  1.6309e-01, -1.8311e-02,  1.0620e-02,\n",
       "         1.3672e-01, -6.2500e-02,  1.3770e-01], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_embeddings[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae1505b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorial-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
